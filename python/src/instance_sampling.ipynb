{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of a random k-SAT dataset\n",
    "\n",
    "Start by generating satisfiable k-SAT instances in k-CNF form and the corresponding solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(r\"../\")\n",
    "import numpy as np\n",
    "from generate_random_instances import generate_dataset_random_kcnf\n",
    "\n",
    "path = #TODO #specify the path where you want to save the dataset\n",
    "\n",
    "num_samples = 5 #number of samples per alpha and n\n",
    "n_list = [100] #n values investiagated\n",
    "alpha_list = np.linspace(1, 5, 21) #list of alpha values investigated\n",
    "k = 3 #locality of the clauses\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    print(\"alpha =\", alpha)\n",
    "    generate_dataset_random_kcnf(\n",
    "        k, n_list, alpha, num_samples, path, vary_percent=0, timeout=10\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need candidates, as specified in the solution. We get them by running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import create_candidates\n",
    "path = \"../../Data/random_sat_data/training/\"  #TODO #specify the path where you want to save the dataset where you want to generate candidates\n",
    "sample_size = 500 #number of candidates generated\n",
    "threshold = 0.3 #specifies how much the candidates vary from the solution used as an input (ratio of flipped variables)\n",
    "create_candidates(path, sample_size, threshold, alternative=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import create_candidates\n",
    "import os\n",
    "\n",
    "# if you want to generate candidates for all the datasets in the directory\n",
    "\n",
    "path = \"../../Data/random_sat_data/\" #specify the path where you want to save the dataset where you want to generate candidates\n",
    "sample_size = 500 #number of candidates generated\n",
    "threshold = 0.3 #specifies how much the candidates vary from the solution used as an input (ratio of flipped variables)\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for dir in dirs:\n",
    "        print(dir)\n",
    "        create_candidates(os.path.join(root, dir), sample_size, threshold, alternative=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of pseudo-industrial datasets\n",
    "\n",
    "In case you want to play around with the pseudo-industrial instance generation, please use the following repository: <https://github.com/zhaoyu-li/G4SATBench> which we also used for instance generation.\n",
    "\n",
    "Please note that you need to have solutions for the satisfiable instances you want to consider. For this, you can make use of the functions `create_solutions_from_cnf(path, time_limit=MAX_TIME)` and `create_solutions_from_gzip(path, time_limit=MAX_TIME)` in `data_utils.py`.\n",
    "\n",
    "To generate candidates, please proceed as done above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
